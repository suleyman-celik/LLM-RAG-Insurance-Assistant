{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d59be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e77f180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/documents-with-ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902363d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'receive_payment',\n",
       " 'question': 'i got to receive fucking compensations can i get some ehlp',\n",
       " 'response': 'To process your compensation payment for the insurance claim, please adhere to the following steps:\\n\\n1. Access your account by visiting {{WEBSITE_URL}}.\\n2. Locate the {{CLAIM_SECTION}} for your specific claim.\\n3. Identify the claim that you wish to be compensated for.\\n4. Opt for the {{RECEIVE_PAYMENT_OPTION}} that best suits your preference.\\n5. Follow the provided instructions to finalize your preferred method of payment and validate the information.\\n\\nShould you face any complications during this process, do not hesitate to reach out to our customer support team for immediate assistance.',\n",
       " 'category': 'CLAIMS',\n",
       " 'id': 'da0592e6'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e36714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are emulating a real customer contacting an insurance company's support.\n",
    "Based on the following FAQ record, generate 5 natural questions the customer\n",
    "might ask to get the same information. \n",
    "\n",
    "Guidelines:\n",
    "- Each question should be clear, concise, and sound like something a real customer would say.  \n",
    "- Do not reuse exact wording from the FAQ record — rephrase naturally.  \n",
    "- Ensure all questions are relevant to the intent.  \n",
    "- Cover variations (short, direct, polite, urgent, explanatory).  \n",
    "- Keep questions simple and customer-friendly.  \n",
    "\n",
    "FAQ record:\n",
    "intent: {intent}\n",
    "question: {question}\n",
    "response: {response}\n",
    "\n",
    "Return only valid JSON in this format (no explanations, no code blocks):\n",
    "\n",
    "{{\n",
    "  \"questions\": [\n",
    "    \"question1\",\n",
    "    \"question2\",\n",
    "    \"question3\",\n",
    "    \"question4\",\n",
    "    \"question5\"\n",
    "  ]\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da40763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")\n",
    "\n",
    "def generate_questions(doc):\n",
    "    prompt = prompt_template.format(**doc)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='phi3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    json_response = response.choices[0].message.content\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a98a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8f539ebcc74ff1bb705f5252c3bf83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for doc in tqdm(documents): \n",
    "    doc_id = doc['id']\n",
    "    if doc_id in results:\n",
    "        continue\n",
    "\n",
    "    questions = generate_questions(doc)\n",
    "    results[doc_id] = questions\n",
    "    with open('my_dict.json', 'w') as json_file:\n",
    "        json.dump(results, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141c5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# # worker function for parallel execution\n",
    "# def process_doc(doc):\n",
    "#     doc_id = doc[\"id\"]\n",
    "#     questions = generate_questions(doc)  # your existing function\n",
    "#     return doc_id, questions\n",
    "\n",
    "# results = {}\n",
    "\n",
    "# # ThreadPoolExecutor with, say, 8 workers (tune this for your M1 Mac)\n",
    "# with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "#     # submit all tasks\n",
    "#     futures = {executor.submit(process_doc, doc): doc for doc in documents}\n",
    "    \n",
    "#     # iterate over results as they complete\n",
    "#     for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "#         doc_id, questions = future.result()\n",
    "#         results[doc_id] = questions\n",
    "        \n",
    "#         # write progressively so you don’t lose progress\n",
    "#         with open(\"my_dict.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "#             json.dump(results, json_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "# print(\"✅ Parallel processing complete. Results saved to my_dict.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdf687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf5d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed99a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3ee912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e413d2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641c35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e355e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
